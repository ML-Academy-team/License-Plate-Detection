{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-ocr"
      ],
      "metadata": {
        "id": "6ZEr7z9hy3Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4uvFrWVQ6SU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!gdown --id '1mOMS71hXclgOWmRZ8O18HCTum3kzERZ5'\n",
        "!gdown --id '1R2SY1LNK1i4G1Mg-EYXyn4Ep__l91C9z'\n",
        "!gdown --id '1LFN1BD1fFN9vkFxACCuFFOZS1VHiRpTW'\n",
        "!gdown --id '1-3KXdRBLJGT-ZESZPdHmqUCTHOJzvbeT'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFSVFB359TLi"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from zipfile import ZipFile\n",
        "files = ['license_plates_detection_train.zip', 'test.zip']\n",
        "parent_dir = \"dataset/\"\n",
        "\n",
        "for file_name in files:\n",
        "  zf = ZipFile(file_name, 'r')\n",
        "  zf.extractall(parent_dir)\n",
        "  zf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txhY2qZtBHje"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! mkdir dataset/train_data\n",
        "! mkdir dataset/test_data\n",
        "! mv -v /content/dataset/license_plates_detection_train/* /content/dataset/train_data\n",
        "! mv -v /content/dataset/test_private/* /content/dataset/test_data\n",
        "! rm -r /content/dataset/license_plates_detection_train /content/dataset/test_private/\n",
        "! mv license_plates_detection_train.csv dataset/train_target.csv\n",
        "! rm license_plates_detection_train.zip test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-xet4Y1NpPy",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbWlaP6AbV3J"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"dataset\"\n",
        "IMAGES_PATH = os.path.sep.join([BASE_PATH, \"train_data\"])\n",
        "LEBELS_PATH = os.path.sep.join([BASE_PATH, \"train_target.csv\"])\n",
        "TEST_IMAGES_PATH = os.path.sep.join([BASE_PATH, \"test_data/\"])\n",
        "CROPPED_IMAGES_PATH = os.path.sep.join([BASE_PATH, \"cropped_license/\"])\n",
        "\n",
        "BASE_OUTPUT = \"output\"\n",
        "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"detector.h5\"])\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "\n",
        "# initialize our initial learning rate, number of epochs to train\n",
        "# for, and the batch size\n",
        "INIT_LR = 1e-4\n",
        "NUM_EPOCHS = 250\n",
        "BATCH_SIZE = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explore the dateset"
      ],
      "metadata": {
        "id": "EKLCc0a1DIYb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbEXf4_dgVBp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(LEBELS_PATH)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA1fQr9XoEvG"
      },
      "outputs": [],
      "source": [
        "row = df.loc[[400]]\n",
        "frame = cv2.imread(os.path.join(IMAGES_PATH,row['img_id'].item()))\n",
        "xmin, ymin = row['xmin'].item(), row['ymin'].item()\n",
        "xmax, ymax = row['xmax'].item(), row['ymax'].item()\n",
        "\n",
        "p_frame = cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0,0,255), 1)\n",
        "p_frame = cv2.circle(p_frame,(xmin,ymin),5,(0,0,255),-1)\n",
        "p_frame = cv2.circle(p_frame,(xmax,ymax),5,(0,0,255),-1)\n",
        "cv2_imshow(p_frame)\n",
        "print(p_frame.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5GC2gjozyXl"
      },
      "outputs": [],
      "source": [
        "(h, w) = (p_frame.shape[:2])\n",
        "targetSize= 224\n",
        "print(f'width: {w}, height:{h}')\n",
        "print(f'xmin:{xmin},ymin:{ymin}, xmax:{xmax}, ymax:{ymax}')\n",
        "\n",
        "x_scale = targetSize / w\n",
        "y_scale = targetSize / h\n",
        "print(f'x_scale: {x_scale}, y_scale:{y_scale}')\n",
        "\n",
        "resized_xmin = xmin / w\n",
        "resized_ymin = ymin / h\n",
        "resized_xmax = xmax / w\n",
        "resized_ymax = ymax / h\n",
        "\n",
        "print(f'new width: {targetSize}, new height:{targetSize}')\n",
        "print(f'resized_xmin:{resized_xmin},resized_ymin:{resized_ymin}, resized_xmax:{resized_xmax}, resized_ymax:{resized_ymax}')\n",
        "\n",
        "resized_xmin = int(np.round(resized_xmin*targetSize))\n",
        "resized_ymin = int(np.round(resized_ymin*targetSize))\n",
        "resized_xmax = int(np.round(resized_xmax*targetSize))\n",
        "resized_ymax = int(np.round(resized_ymax*targetSize))\n",
        "\n",
        "img = cv2.imread(os.path.join(IMAGES_PATH,row['img_id'].item()))\n",
        "\n",
        "resized_img = cv2.resize(img, (targetSize, targetSize));\n",
        "resized_img = cv2.rectangle(resized_img, (resized_xmin, resized_ymin), (resized_xmax, resized_ymax), (0,0,255), 1)\n",
        "cv2_imshow(resized_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Training and validation loaders"
      ],
      "metadata": {
        "id": "HsOmiKQ9DMND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oahAj0yCb92i"
      },
      "outputs": [],
      "source": [
        "print(\"Creating the Training and validation loaders ...\")\n",
        "\n",
        "data = []\n",
        "targets = []\n",
        "filenames = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  filename = row['img_id']\n",
        "  xmin, ymin = row['xmin'], row['ymin']\n",
        "  xmax, ymax = row['xmax'], row['ymax']\n",
        "  \n",
        "  imagePath = os.path.sep.join([IMAGES_PATH, filename])\n",
        "  image = cv2.imread(imagePath)\n",
        "  (h, w) = (image.shape[:2])\n",
        "\n",
        "  resized_xmin = xmin / w\n",
        "  resized_ymin = ymin / h\n",
        "  resized_xmax = xmax / w\n",
        "  resized_ymax = ymax / h\n",
        "\n",
        "  image = load_img(imagePath, target_size=(224, 224))\n",
        "  image = img_to_array(image)\n",
        "\n",
        "  data.append(image)\n",
        "  targets.append((resized_xmin, resized_ymin, resized_xmax, resized_ymax))\n",
        "  filenames.append(filename)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "targets = np.array(targets, dtype=\"float32\")\n",
        "\n",
        "split = train_test_split(data, targets, filenames, test_size=0.20,\n",
        "    random_state=123)\n",
        "\n",
        "(trainImages, testImages) = split[:2]\n",
        "(trainTargets, testTargets) = split[2:4]\n",
        "(trainFilenames, testFilenames) = split[4:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model creation and training"
      ],
      "metadata": {
        "id": "WYuiQADfAX43"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcC1vfsad9k3"
      },
      "outputs": [],
      "source": [
        "from numpy.core.numeric import True_\n",
        "\n",
        "resnet50 = ResNet50(include_top=False, weights='imagenet', input_tensor=Input(shape=(224, 224, 3)))\n",
        "resnet50.trainable = True\n",
        "\n",
        "flatten = resnet50.output\n",
        "flatten = Flatten()(flatten)\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
        "\n",
        "model = Model(inputs=resnet50.input, outputs=bboxHead)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTF0hc56eOdL",
        "outputId": "ec992c9c-c384-4ae2-e043-7b5ce22c1f47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 100352)       0           ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          51380736    ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          65664       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           4128        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4)            132         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 75,038,372\n",
            "Trainable params: 74,985,252\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[INFO] training bounding box regressor...\n",
            "Epoch 1/250\n",
            "72/72 [==============================] - 33s 344ms/step - loss: 1.8988e-04 - val_loss: 0.0029\n",
            "Epoch 2/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 7.5651e-04 - val_loss: 0.0031\n",
            "Epoch 3/250\n",
            "72/72 [==============================] - 23s 323ms/step - loss: 7.5924e-04 - val_loss: 0.0021\n",
            "Epoch 4/250\n",
            "72/72 [==============================] - 23s 320ms/step - loss: 6.5546e-04 - val_loss: 0.0028\n",
            "Epoch 5/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.8008e-04 - val_loss: 0.0033\n",
            "Epoch 6/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 3.8224e-04 - val_loss: 0.0019\n",
            "Epoch 7/250\n",
            "72/72 [==============================] - 23s 320ms/step - loss: 3.1786e-04 - val_loss: 0.0017\n",
            "Epoch 8/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.7122e-04 - val_loss: 0.0018\n",
            "Epoch 9/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.1377e-04 - val_loss: 0.0018\n",
            "Epoch 10/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.7856e-04 - val_loss: 0.0019\n",
            "Epoch 11/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.1929e-04 - val_loss: 0.0019\n",
            "Epoch 12/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.0805e-04 - val_loss: 0.0018\n",
            "Epoch 13/250\n",
            "72/72 [==============================] - 23s 320ms/step - loss: 1.0271e-04 - val_loss: 0.0017\n",
            "Epoch 14/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 9.2448e-05 - val_loss: 0.0016\n",
            "Epoch 15/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 8.4800e-05 - val_loss: 0.0017\n",
            "Epoch 16/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 7.9168e-05 - val_loss: 0.0017\n",
            "Epoch 17/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 7.8809e-05 - val_loss: 0.0017\n",
            "Epoch 18/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 8.4520e-05 - val_loss: 0.0017\n",
            "Epoch 19/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 8.3009e-05 - val_loss: 0.0017\n",
            "Epoch 20/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 7.5466e-05 - val_loss: 0.0018\n",
            "Epoch 21/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 7.7507e-05 - val_loss: 0.0017\n",
            "Epoch 22/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 7.7802e-05 - val_loss: 0.0017\n",
            "Epoch 23/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 7.0211e-05 - val_loss: 0.0017\n",
            "Epoch 24/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 6.9878e-05 - val_loss: 0.0017\n",
            "Epoch 25/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 8.6052e-05 - val_loss: 0.0017\n",
            "Epoch 26/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 9.3834e-05 - val_loss: 0.0018\n",
            "Epoch 27/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 7.7113e-05 - val_loss: 0.0016\n",
            "Epoch 28/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 7.1741e-05 - val_loss: 0.0017\n",
            "Epoch 29/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 7.5625e-05 - val_loss: 0.0016\n",
            "Epoch 30/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 8.2145e-05 - val_loss: 0.0016\n",
            "Epoch 31/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 8.4834e-05 - val_loss: 0.0015\n",
            "Epoch 32/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 9.3603e-05 - val_loss: 0.0019\n",
            "Epoch 33/250\n",
            "72/72 [==============================] - 23s 320ms/step - loss: 1.0007e-04 - val_loss: 0.0014\n",
            "Epoch 34/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.0012e-04 - val_loss: 0.0017\n",
            "Epoch 35/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 9.5802e-05 - val_loss: 0.0015\n",
            "Epoch 36/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.0333e-04 - val_loss: 0.0016\n",
            "Epoch 37/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 9.0343e-05 - val_loss: 0.0014\n",
            "Epoch 38/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.0515e-04 - val_loss: 0.0014\n",
            "Epoch 39/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 1.0376e-04 - val_loss: 0.0015\n",
            "Epoch 40/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 8.5502e-05 - val_loss: 0.0016\n",
            "Epoch 41/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 7.7321e-05 - val_loss: 0.0015\n",
            "Epoch 42/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 6.0964e-05 - val_loss: 0.0015\n",
            "Epoch 43/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 5.8046e-05 - val_loss: 0.0016\n",
            "Epoch 44/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.7937e-05 - val_loss: 0.0015\n",
            "Epoch 45/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.1160e-05 - val_loss: 0.0015\n",
            "Epoch 46/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.9372e-05 - val_loss: 0.0014\n",
            "Epoch 47/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.6560e-05 - val_loss: 0.0017\n",
            "Epoch 48/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.4141e-05 - val_loss: 0.0016\n",
            "Epoch 49/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.3853e-05 - val_loss: 0.0016\n",
            "Epoch 50/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 4.7326e-05 - val_loss: 0.0018\n",
            "Epoch 51/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.0713e-04 - val_loss: 0.0016\n",
            "Epoch 52/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 9.8798e-05 - val_loss: 0.0016\n",
            "Epoch 53/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.1722e-04 - val_loss: 0.0015\n",
            "Epoch 54/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 1.0466e-04 - val_loss: 0.0014\n",
            "Epoch 55/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 8.7738e-05 - val_loss: 0.0015\n",
            "Epoch 56/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.9863e-05 - val_loss: 0.0015\n",
            "Epoch 57/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.4255e-05 - val_loss: 0.0016\n",
            "Epoch 58/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 5.3452e-05 - val_loss: 0.0016\n",
            "Epoch 59/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 5.4572e-05 - val_loss: 0.0015\n",
            "Epoch 60/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 5.4801e-05 - val_loss: 0.0015\n",
            "Epoch 61/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 4.5721e-05 - val_loss: 0.0016\n",
            "Epoch 62/250\n",
            "72/72 [==============================] - 23s 320ms/step - loss: 4.0261e-05 - val_loss: 0.0014\n",
            "Epoch 63/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 4.0454e-05 - val_loss: 0.0014\n",
            "Epoch 64/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 4.2215e-05 - val_loss: 0.0016\n",
            "Epoch 65/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 3.6628e-05 - val_loss: 0.0015\n",
            "Epoch 66/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.2959e-05 - val_loss: 0.0015\n",
            "Epoch 67/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.4526e-05 - val_loss: 0.0014\n",
            "Epoch 68/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 2.7893e-05 - val_loss: 0.0014\n",
            "Epoch 69/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.4588e-05 - val_loss: 0.0014\n",
            "Epoch 70/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.8759e-05 - val_loss: 0.0014\n",
            "Epoch 71/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 4.3299e-05 - val_loss: 0.0015\n",
            "Epoch 72/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.3487e-05 - val_loss: 0.0015\n",
            "Epoch 73/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.6514e-05 - val_loss: 0.0014\n",
            "Epoch 74/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.4072e-05 - val_loss: 0.0014\n",
            "Epoch 75/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.5794e-05 - val_loss: 0.0015\n",
            "Epoch 76/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.5082e-05 - val_loss: 0.0014\n",
            "Epoch 77/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.5154e-05 - val_loss: 0.0015\n",
            "Epoch 78/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.6153e-05 - val_loss: 0.0017\n",
            "Epoch 79/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 4.7538e-05 - val_loss: 0.0014\n",
            "Epoch 80/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.9547e-05 - val_loss: 0.0015\n",
            "Epoch 81/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 4.6834e-05 - val_loss: 0.0014\n",
            "Epoch 82/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 3.8139e-05 - val_loss: 0.0014\n",
            "Epoch 83/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.2553e-05 - val_loss: 0.0015\n",
            "Epoch 84/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.2915e-05 - val_loss: 0.0014\n",
            "Epoch 85/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.3258e-05 - val_loss: 0.0014\n",
            "Epoch 86/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.1163e-05 - val_loss: 0.0015\n",
            "Epoch 87/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 4.5655e-05 - val_loss: 0.0013\n",
            "Epoch 88/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 5.2506e-05 - val_loss: 0.0014\n",
            "Epoch 89/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.8021e-05 - val_loss: 0.0015\n",
            "Epoch 90/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.5039e-05 - val_loss: 0.0014\n",
            "Epoch 91/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 4.3272e-05 - val_loss: 0.0013\n",
            "Epoch 92/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 3.6077e-05 - val_loss: 0.0014\n",
            "Epoch 93/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.9151e-05 - val_loss: 0.0014\n",
            "Epoch 94/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.9083e-05 - val_loss: 0.0014\n",
            "Epoch 95/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.5147e-05 - val_loss: 0.0014\n",
            "Epoch 96/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.2676e-05 - val_loss: 0.0015\n",
            "Epoch 97/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 2.9425e-05 - val_loss: 0.0014\n",
            "Epoch 98/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 2.9960e-05 - val_loss: 0.0015\n",
            "Epoch 99/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.8651e-05 - val_loss: 0.0014\n",
            "Epoch 100/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.9778e-05 - val_loss: 0.0013\n",
            "Epoch 101/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.0750e-05 - val_loss: 0.0014\n",
            "Epoch 102/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.2852e-05 - val_loss: 0.0016\n",
            "Epoch 103/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 3.9093e-05 - val_loss: 0.0014\n",
            "Epoch 104/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 4.4158e-05 - val_loss: 0.0014\n",
            "Epoch 105/250\n",
            "72/72 [==============================] - 23s 321ms/step - loss: 6.1826e-05 - val_loss: 0.0013\n",
            "Epoch 106/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 6.5424e-05 - val_loss: 0.0014\n",
            "Epoch 107/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 5.0053e-05 - val_loss: 0.0015\n",
            "Epoch 108/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 3.9211e-05 - val_loss: 0.0014\n",
            "Epoch 109/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.1008e-05 - val_loss: 0.0014\n",
            "Epoch 110/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.7396e-05 - val_loss: 0.0014\n",
            "Epoch 111/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 3.5262e-05 - val_loss: 0.0015\n",
            "Epoch 112/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.2014e-05 - val_loss: 0.0014\n",
            "Epoch 113/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.3688e-05 - val_loss: 0.0015\n",
            "Epoch 114/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.8599e-05 - val_loss: 0.0014\n",
            "Epoch 115/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.6316e-05 - val_loss: 0.0013\n",
            "Epoch 116/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.6593e-05 - val_loss: 0.0014\n",
            "Epoch 117/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.5488e-05 - val_loss: 0.0013\n",
            "Epoch 118/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.3899e-05 - val_loss: 0.0015\n",
            "Epoch 119/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.3587e-05 - val_loss: 0.0013\n",
            "Epoch 120/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.3912e-05 - val_loss: 0.0014\n",
            "Epoch 121/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.2035e-05 - val_loss: 0.0013\n",
            "Epoch 122/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.0609e-05 - val_loss: 0.0014\n",
            "Epoch 123/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.2995e-05 - val_loss: 0.0014\n",
            "Epoch 124/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.5799e-05 - val_loss: 0.0014\n",
            "Epoch 125/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.5800e-05 - val_loss: 0.0014\n",
            "Epoch 126/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.8492e-05 - val_loss: 0.0014\n",
            "Epoch 127/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.0181e-05 - val_loss: 0.0013\n",
            "Epoch 128/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.9585e-05 - val_loss: 0.0013\n",
            "Epoch 129/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.7101e-05 - val_loss: 0.0014\n",
            "Epoch 130/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.5855e-05 - val_loss: 0.0014\n",
            "Epoch 131/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.8511e-05 - val_loss: 0.0014\n",
            "Epoch 132/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.7948e-05 - val_loss: 0.0014\n",
            "Epoch 133/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.7476e-05 - val_loss: 0.0015\n",
            "Epoch 134/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.6448e-05 - val_loss: 0.0015\n",
            "Epoch 135/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 3.0572e-05 - val_loss: 0.0014\n",
            "Epoch 136/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 3.5442e-05 - val_loss: 0.0013\n",
            "Epoch 137/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 3.8743e-05 - val_loss: 0.0013\n",
            "Epoch 138/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 3.7189e-05 - val_loss: 0.0014\n",
            "Epoch 139/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 3.0779e-05 - val_loss: 0.0014\n",
            "Epoch 140/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 2.6957e-05 - val_loss: 0.0014\n",
            "Epoch 141/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.2009e-05 - val_loss: 0.0013\n",
            "Epoch 142/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.2430e-05 - val_loss: 0.0014\n",
            "Epoch 143/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 2.3063e-05 - val_loss: 0.0014\n",
            "Epoch 144/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.9093e-05 - val_loss: 0.0013\n",
            "Epoch 145/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.8545e-05 - val_loss: 0.0013\n",
            "Epoch 146/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.9834e-05 - val_loss: 0.0014\n",
            "Epoch 147/250\n",
            "72/72 [==============================] - 23s 317ms/step - loss: 1.9696e-05 - val_loss: 0.0014\n",
            "Epoch 148/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.8842e-05 - val_loss: 0.0014\n",
            "Epoch 149/250\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 1.6903e-05 - val_loss: 0.0014\n",
            "Epoch 150/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.7988e-05 - val_loss: 0.0014\n",
            "Epoch 151/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 1.9992e-05 - val_loss: 0.0014\n",
            "Epoch 152/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.4291e-05 - val_loss: 0.0014\n",
            "Epoch 153/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.2408e-05 - val_loss: 0.0014\n",
            "Epoch 154/250\n",
            "72/72 [==============================] - 23s 318ms/step - loss: 2.2777e-05 - val_loss: 0.0013\n",
            "Epoch 155/250\n",
            "72/72 [==============================] - ETA: 0s - loss: 2.2960e-05Restoring model weights from the end of the best epoch: 105.\n",
            "72/72 [==============================] - 23s 319ms/step - loss: 2.2960e-05 - val_loss: 0.0015\n",
            "Epoch 00155: early stopping\n"
          ]
        }
      ],
      "source": [
        "opt = Adam(lr=INIT_LR)\n",
        "model.compile(loss=\"mse\", optimizer=opt)\n",
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=50, verbose=1,\n",
        "    mode='auto', baseline=None, restore_best_weights=True\n",
        ")\n",
        "print(model.summary())\n",
        "\n",
        "print(\"[INFO] training bounding box regressor...\")\n",
        "with tf.device('/device:GPU:0'):\n",
        "\tH = model.fit(\n",
        "\t\ttrainImages, trainTargets,\n",
        "\t\tvalidation_data=(testImages, testTargets),\n",
        "\t\tbatch_size=BATCH_SIZE,\n",
        "\t\tepochs=NUM_EPOCHS,\n",
        "\t\tcallbacks=[callback],\n",
        "\t\tverbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the model checkpoint and visualizing the training metrics"
      ],
      "metadata": {
        "id": "grwnUq_UDYn_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "QMAr4mlbeWOU",
        "outputId": "8050c8b4-8ac7-4a34-e04c-35a93c70fceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] saving object detector model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving object detector model...\")\n",
        "model.save(MODEL_PATH, save_format=\"h5\")\n",
        "# plot the model training history\n",
        "N = 155\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(PLOT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the model performance with the test data and extracting the licenses from the images"
      ],
      "metadata": {
        "id": "ghwTDRXuAQH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPLhArmfFVIx"
      },
      "outputs": [],
      "source": [
        "imagePaths = []\n",
        "for f in os.listdir(TEST_IMAGES_PATH):\n",
        "  abspath = TEST_IMAGES_PATH + f\n",
        "  imagePaths.append(abspath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNETnLbKe83F"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"[INFO] loading object detector...\")\n",
        "model = load_model('/content/detector.h5')\n",
        "\n",
        "target_size = 224\n",
        "if not os.path.exists(CROPPED_IMAGES_PATH):\n",
        "    os.makedirs(CROPPED_IMAGES_PATH)\n",
        "\n",
        "for count, imagePath in enumerate(imagePaths):\n",
        "\n",
        "    img_name = os.path.basename(imagePath)\n",
        "    image = load_img(imagePath, target_size=(224, 224))\n",
        "    image = img_to_array(image) / 255.0\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    preds = model.predict(image)[0]\n",
        "    (startX, startY, endX, endY) = preds\n",
        "\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = imutils.resize(image, width=600)\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    xmin = int(np.round(startX*w))\n",
        "    ymin = int(np.round(startY*h))\n",
        "    xmax = int(np.round(endX*w))\n",
        "    ymax = int(np.round(endY*h))    \n",
        "    #draw the predicted bounding box on the image\n",
        "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax),\n",
        "        (0, 255, 0), 2)\n",
        "    #Crop the license plates from the orginal images.    \n",
        "    cropped_lp = image[ymin:ymax, xmin:xmax, :]\n",
        "    # save cropped_image\n",
        "    img_name = \"cropped_\"+img_name\n",
        "    cv2.imwrite(os.path.join(CROPPED_IMAGES_PATH, img_name), cropped_lp)\n",
        "    if(count<5):\n",
        "      # show the output image\n",
        "      cv2_imshow(image)\n",
        "      cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Licence plate recognition on the cropped licenses using Keras Optical Characters Recognition"
      ],
      "metadata": {
        "id": "2KELQq81tYM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crop_imagePaths = []\n",
        "for f in os.listdir(CROPPED_IMAGES_PATH):\n",
        "  abspath = CROPPED_IMAGES_PATH + f\n",
        "  crop_imagePaths.append(abspath)"
      ],
      "metadata": {
        "id": "-Gq-KCI7s0tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_ocr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pipeline = keras_ocr.pipeline.Pipeline()\n",
        "\n",
        "images = [\n",
        "   keras_ocr.tools.read(img_abspath) for img_abspath in crop_imagePaths\n",
        "]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4FIYnU2s1U4",
        "outputId": "a194595a-b547-4d55-beac-d91641f4e1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Looking for /root/.keras-ocr/crnn_kurapan.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_groups = pipeline.recognize(images)"
      ],
      "metadata": {
        "id": "D2P4c7iutLC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, predictions, img_abspath in zip(images, prediction_groups, crop_imagePaths):\n",
        "    npl = list()\n",
        "    license_plate = ''\n",
        "    for p in predictions:\n",
        "      if (p[0].isdecimal()):\n",
        "        npl.append(p[0])\n",
        "      else:\n",
        "        continue \n",
        "    for n in npl:\n",
        "      license_plate += n\n",
        "      license_plate += ' '\n",
        "    print(img_abspath)\n",
        "    print(f'License plate: {license_plate}') "
      ],
      "metadata": {
        "id": "aXwDBSwWtR6c"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "VGG16_Plate_Detection (4).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}